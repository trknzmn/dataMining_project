{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ÖN İŞLEMEYE DAİR\n",
    "\"Z-SKORU İLE NUMERİK SÜTUNLARDA AYKIRI DEĞER TESPİTİ VE CLIPPING\"\n",
    "\"PRICE SÜTUNU İÇİN LOG DÖNÜŞÜMÜ\"\n",
    "def handle_outliers_zscore(df, threshold=3):\n",
    "    \"\"\"\n",
    "    Sayısal sütunlardaki aykırı değerleri Z-skoru yöntemiyle tespit eder ve yönetir.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Veri çerçevesi.\n",
    "        threshold (float): Z-skoru eşik değeri.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Aykırı değerleri yönetilmiş veri çerçevesi.\n",
    "    \"\"\"\n",
    "\n",
    "    df_numeric = df.select_dtypes(include=np.number)  # Sadece sayısal sütunlar\n",
    "\n",
    "    for col in df_numeric.columns:\n",
    "        if col == 'price':  # Fiyat sütununu ayrıca ele al\n",
    "            continue\n",
    "\n",
    "        mean = df[col].mean()\n",
    "        std = df[col].std()\n",
    "        z_scores = np.abs((df[col] - mean) / std)\n",
    "        outlier_indices = np.where(z_scores > threshold)[0]\n",
    "        num_outliers = len(outlier_indices)\n",
    "\n",
    "        if num_outliers > 0:\n",
    "            print(f\"Sütun: {col}, Aykırı Değer Sayısı: {num_outliers}\")\n",
    "            # Aykırı değerleri görselleştir (boxplot)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.boxplot(x=df[col])\n",
    "            plt.title(f\"Sütun: {col} - Aykırı Değerler\")\n",
    "            plt.show()\n",
    "\n",
    "            # Sınırlama (Clipping)\n",
    "            df[col] = np.where(df[col] > mean + threshold * std, mean + threshold * std, df[col])\n",
    "            df[col] = np.where(df[col] < mean - threshold * std, mean - threshold * std, df[col])\n",
    "\n",
    "            print(f\"Sütun: {col}, Aykırı Değerler Sınırlandırıldı.\")\n",
    "\n",
    "    # Fiyat sütununu ayrıca ele al (log dönüşümü)\n",
    "    if 'price' in df.columns:\n",
    "        print(\"Fiyat sütununa log dönüşümü uygulanıyor...\")\n",
    "        df['price'] = np.log1p(df['price'])  # log1p, log(1 + x) demektir\n",
    "        print(\"Fiyat sütununa log dönüşümü uygulandı.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# Aykırı değerleri yönet\n",
    "df = handle_outliers_zscore(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"train_test_split() YERİNE ÇAPRAZ DOĞRULAMA\"\n",
    "\n",
    "# Çapraz doğrulama stratejisini tanımla\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # 5 katlı çapraz doğrulama\n",
    "\n",
    "# Performansı saklamak için listeler\n",
    "accuracy_scores = []\n",
    "classification_reports = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Çapraz doğrulama döngüsü\n",
    "for fold, (train_index, test_index) in enumerate(cv.split(X, y)):\n",
    "    print(f\"\\nFold {fold + 1}\")\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Modeli eğit\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Tahmin yap\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Performansı değerlendir\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    accuracy_scores.append(accuracy)\n",
    "    classification_reports.append(report)\n",
    "    confusion_matrices.append(cm)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(report)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "# Ortalama performansı yazdır\n",
    "print(\"\\nOrtalama Performans\")\n",
    "print(f\"Ortalama Accuracy: {np.mean(accuracy_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"MODEL HİPERPARAMETRELERİ OPTİMİZASYONU - GridSearchCV\"\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "#Hiperparametre optimizasyonu sırasında kullanılan doğrulama verisi ile modelin nihai \n",
    "# performansını değerlendirmek için kullanılan test verisinin tamamen ayrı olduğundan emin olunmalıdır.\n",
    "\n",
    "# Veri setini eğitim ve test kümelerine ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=42, stratify=y) \n",
    "\n",
    "# Model tanımlama\n",
    "model = SVC(random_state=42)\n",
    "\n",
    "# Hiperparametre optimizasyonu\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['rbf', 'linear'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid, cv=cv, verbose=2,n_jobs=-1)  # Tüm veriyle eğitiyoruz.\n",
    "grid_search.fit(X_train, y_train)  # Sadece eğitim verisiyle eğitiyoruz\n",
    "best_model = grid_search.best_estimator_  # En iyi modeli al\n",
    "\n",
    "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
    "print(\"En iyi skor:\", grid_search.best_score_)\n",
    "\n",
    "# Test seti üzerinde değerlendirme\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "report_test = classification_report(y_test, y_pred_test)\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "print(\"\\nTest Seti Performansı:\")\n",
    "print(f\"Accuracy: {accuracy_test:.4f}\")\n",
    "print(report_test)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_test)\n",
    "\n",
    "#Bu kod, en iyi parametreleri bulur ve ekrana yazdırır.\n",
    "#Modeli bu parametrelerle eğitmek için best_model değişkenini kullanabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"ÖZNİTELİK SEÇİMİ YÖNTEMLERİ (RFE, ANOVA, Ki-Kare, Lasso) İLE OPTİMİZASYON\"\n",
    "\n",
    "n_features = 10  # Seçilecek öznitelik sayısı\n",
    "\n",
    "# RFE (Recursive Feature Elimination)\n",
    "rfe = RFE(estimator=SVC(kernel='linear', random_state=42), n_features_to_select=n_features)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "selected_features_rfe = X_train.columns[rfe.support_]\n",
    "\n",
    "# SelectKBest (ANOVA)\n",
    "anova = SelectKBest(score_func=f_classif, k=n_features)\n",
    "X_train_anova = anova.fit_transform(X_train, y_train)\n",
    "X_test_anova = anova.transform(X_test)\n",
    "selected_features_anova = X_train.columns[anova.get_support()]\n",
    "\n",
    "# SelectKBest (Ki-kare) - Sadece kategorik verilerle kullanılabilir\n",
    "#categorical_cols tanımlı olmalıdır\n",
    "if len(categorical_cols) > 0:\n",
    "    # Kategorik sütunları Ki-kare testi için uygun formata dönüştürme (gerekirse)\n",
    "    # Bu örnekte, kategorik sütunların zaten uygun formatta olduğunu varsayıyoruz.\n",
    "    X_train_chi2 = X_train[categorical_cols]\n",
    "    X_test_chi2 = X_test[categorical_cols]\n",
    "\n",
    "    chi2_selector = SelectKBest(score_func=chi2, k=n_features)\n",
    "    X_train_chi2_selected = chi2_selector.fit_transform(X_train_chi2, y_train)\n",
    "    X_test_chi2_selected = chi2_selector.transform(X_test_chi2)\n",
    "    selected_features_chi2 = X_train_chi2.columns[chi2_selector.get_support()]\n",
    "else:\n",
    "    selected_features_chi2 = []\n",
    "    \n",
    "# Lasso\n",
    "lasso = Lasso(alpha=0.1, random_state=42)  # alpha değeri ayarlanabilir\n",
    "lasso.fit(X_train, y_train)\n",
    "selected_features_lasso = X_train.columns[lasso.coef_ != 0]\n",
    "X_train_lasso = X_train[selected_features_lasso]\n",
    "X_test_lasso = X_test[selected_features_lasso]\n",
    "#Lasso için alpha parametresi düzenlileştirme gücünü kontrol eder. Farklı alpha değerleri deneyerek en iyi sonucu elde etmeye çalışın.\n",
    "\n",
    "# 3. Sonuçları Karşılaştırma\n",
    "print(f\"Seçilen En İyi {n_features} Özellik:\")\n",
    "print(\"RFE:\", selected_features_rfe)\n",
    "print(\"ANOVA:\", selected_features_anova)\n",
    "print(\"Lasso:\", selected_features_lasso.tolist())\n",
    "if len(categorical_cols) > 0:\n",
    "    print(\"Ki-kare:\", selected_features_chi2)\n",
    "\n",
    "# 4. Performansı Değerlendirme (İsteğe Bağlı)\n",
    "# Bu bölümde, seçilen özelliklerle bir model eğitip performansını karşılaştırabilirsiniz.\n",
    "# Örneğin, SVC ile deneyebilirsiniz:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# RFE ile seçilen özelliklerle model eğitimi ve değerlendirme\n",
    "model_rfe = SVC(random_state=42)\n",
    "model_rfe.fit(X_train_rfe, y_train)\n",
    "y_pred_rfe = model_rfe.predict(X_test_rfe)\n",
    "print(\"\\nRFE Performansı:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rfe))\n",
    "print(classification_report(y_test, y_pred_rfe))\n",
    "\n",
    "# ANOVA ile seçilen özelliklerle model eğitimi ve değerlendirme\n",
    "model_anova = SVC(random_state=42)\n",
    "model_anova.fit(X_train_anova, y_train)\n",
    "y_pred_anova = model_anova.predict(X_test_anova)\n",
    "print(\"\\nANOVA Performansı:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_anova))\n",
    "print(classification_report(y_test, y_pred_anova))\n",
    "\n",
    "# Lasso ile seçilen özelliklerle model eğitimi ve değerlendirme\n",
    "model_lasso = SVC(random_state=42)\n",
    "model_lasso.fit(X_train_lasso, y_train)\n",
    "y_pred_lasso = model_lasso.predict(X_test_lasso)\n",
    "print(\"\\nLasso ile Seçilen Özelliklerle Performans:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lasso))\n",
    "print(classification_report(y_test, y_pred_lasso))\n",
    "\n",
    "if len(categorical_cols) > 0:\n",
    "    # Ki-kare ile seçilen özelliklerle model eğitimi ve değerlendirme\n",
    "    model_chi2 = SVC(random_state=42)\n",
    "    model_chi2.fit(X_train_chi2_selected, y_train)\n",
    "    y_pred_chi2 = model_chi2.predict(X_test_chi2_selected)\n",
    "    print(\"\\nKi-kare Performansı:\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_chi2))\n",
    "    print(classification_report(y_test, y_pred_chi2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Veri Dengesizliği Varsa SMOTE ile OverSampling ve Yeni Çapraz Doğrulama Döngüsü\"\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold  # Çapraz doğrulama için\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler  # Sınıf dengeleme için\n",
    "import numpy as np\n",
    "\n",
    "# Çapraz doğrulama stratejisi\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)  # Önemli: stratify=y\n",
    "\n",
    "# Model ve sınıf dengeleme yöntemleri\n",
    "model = SVC(random_state=42)\n",
    "smote = SMOTE(random_state=42)\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Sonuçları saklamak için listeler\n",
    "smote_results = []\n",
    "ros_results = []\n",
    "\n",
    "# Çapraz doğrulama döngüsü\n",
    "for fold, (train_index, val_index) in enumerate(cv.split(X, y)):  # val_index artık doğrulama indeksi\n",
    "    print(f\"\\n--- Katman {fold + 1} ---\")\n",
    "\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]  # .iloc kullan\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    # *Her katmanda ayrı ayrı* sınıf dengeleme\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "    X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Ölçeklendirme (Her katmanda ayrı ayrı)\n",
    "    scaler_smote = StandardScaler()\n",
    "    X_train_smote = scaler_smote.fit_transform(X_train_smote)\n",
    "    X_val_smote = scaler_smote.transform(X_val)  # *Eğitim verisi ölçeklendiricisiyle* doğrulama verisini ölçeklendir\n",
    "\n",
    "    scaler_ros = StandardScaler()\n",
    "    X_train_ros = scaler_ros.fit_transform(X_train_ros)\n",
    "    X_val_ros = scaler_ros.transform(X_val)\n",
    "\n",
    "    # Modelleri eğitme ve değerlendirme\n",
    "    model.fit(X_train_smote, y_train_smote)\n",
    "    y_pred_smote = model.predict(X_val_smote)\n",
    "    smote_results.append(classification_report(y_val, y_pred_smote, output_dict=True))\n",
    "\n",
    "    model.fit(X_train_ros, y_train_ros)\n",
    "    y_pred_ros = model.predict(X_val_ros)\n",
    "    ros_results.append(classification_report(y_val, y_pred_ros, output_dict=True))\n",
    "\n",
    "# Ortalama sonuçları hesaplama (örnek olarak F1-skoru)\n",
    "def average_results(results):\n",
    "    avg_precision = np.mean([r['macro avg']['precision'] for r in results])\n",
    "    avg_recall = np.mean([r['macro avg']['recall'] for r in results])\n",
    "    avg_f1 = np.mean([r['macro avg']['f1-score'] for r in results])\n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "avg_smote_precision, avg_smote_recall, avg_smote_f1 = average_results(smote_results)\n",
    "avg_ros_precision, avg_ros_recall, avg_ros_f1 = average_results(ros_results)\n",
    "\n",
    "print(\"\\n--- Ortalama Sonuçlar (SMOTE) ---\")\n",
    "print(f\"Precision: {avg_smote_precision:.4f}, Recall: {avg_smote_recall:.4f}, F1-skoru: {avg_smote_f1:.4f}\")\n",
    "\n",
    "print(\"\\n--- Ortalama Sonuçlar (RandomOverSampler) ---\")\n",
    "print(f\"Precision: {avg_ros_precision:.4f}, Recall: {avg_ros_recall:.4f}, F1-skoru: {avg_ros_f1:.4f}\")\n",
    "\n",
    " \n",
    "# En iyi sınıf dengeleme yöntemini belirleme (örnek olarak, en yüksek F1-skoru)\n",
    "if avg_smote_f1 > avg_ros_f1:\n",
    "    best_balancer = SMOTE(random_state=42)\n",
    "    X_train_best, y_train_best = best_balancer.fit_resample(X_train, y_train)\n",
    "    print(\"\\nSMOTE en iyi dengeleme yöntemi olarak seçildi.\")\n",
    "else:\n",
    "    best_balancer = RandomOverSampler(random_state=42)\n",
    "    X_train_best, y_train_best = best_balancer.fit_resample(X_train, y_train)\n",
    "    print(\"\\nRandomOverSampler en iyi dengeleme yöntemi olarak seçildi.\")\n",
    "\n",
    "# Tüm eğitim verisi üzerinde en iyi yöntemle yeniden dengeleme\n",
    "X_train_final = scaler.fit_transform(X_train_best)  # Tüm eğitim verisiyle ölçeklendir\n",
    "X_test_final = scaler.transform(X_test)  # Test verisini eğitim ölçeklendiricisiyle ölçeklendir\n",
    "\n",
    "# Modeli tüm eğitim verisiyle eğitme\n",
    "final_model = SVC(random_state=42)  # En iyi hiperparametrelerle (varsa)\n",
    "final_model.fit(X_train_final, y_train_best)\n",
    "\n",
    "# Test verisi üzerinde değerlendirme\n",
    "y_pred_final = final_model.predict(X_test_final)\n",
    "print(\"\\n--- Nihai Model Performansı (Test Verisi Üzerinde) ---\")\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Polinomsal Özellikler Üretme\"\n",
    "\"Veriye uygun değilse veya işleri çok karmaşıklaştırırsa çıkarılabilir -T\"\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Veri setini eğitim ve test kümelerine ayırdıktan ve ölçeklendirdikten sonra (yukarıdaki kodda)\n",
    "# PolynomialFeatures uygulaması\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)  # degree polinomun derecesi\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "print(\"Orijinal Özellik Sayısı:\", X_train.shape[1])\n",
    "print(\"Polinomsal Özellik Sayısı:\", X_train_poly.shape[1])\n",
    "\n",
    "# Modeli polinomsal özelliklerle eğitme\n",
    "model_poly = SVC(random_state=42)\n",
    "model_poly.fit(X_train_poly, y_train)\n",
    "y_pred_poly = model_poly.predict(X_test_poly)\n",
    "\n",
    "print(\"\\nPolinomsal Özelliklerle Model Performansı:\")\n",
    "print(classification_report(y_test, y_pred_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"EKSİK VERİLERİ KNN VEYA REGRESYON İLE DOLDURMA\"\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "\n",
    "def intelligent_imputation(X_train, X_test, numeric_cols, method='knn', n_neighbors=5):\n",
    "    \"\"\"\n",
    "    Eksik değerleri sayısal sütunlarda akıllı yöntemlerle doldurur.\n",
    "\n",
    "    Args:\n",
    "        X_train (pd.DataFrame): Eğitim veri seti.\n",
    "        X_test (pd.DataFrame): Test veri seti.\n",
    "        numeric_cols (list): Sayısal sütunların listesi.\n",
    "        method (str, optional): 'knn' veya 'regression'. Varsayılan 'knn'.\n",
    "        n_neighbors (int, optional): KNN için komşu sayısı. Varsayılan 5.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Eksik değerleri doldurulmuş X_train ve X_test.\n",
    "    \"\"\"\n",
    "\n",
    "    X_train_imputed = X_train.copy()\n",
    "    X_test_imputed = X_test.copy()\n",
    "\n",
    "    for col in numeric_cols:\n",
    "        if X_train[col].isnull().any():  # Sütunda eksik değer varsa\n",
    "            print(f\"\\nSütun: {col}\")\n",
    "\n",
    "            if method == 'knn':\n",
    "                imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "                X_train_imputed[[col]] = imputer.fit_transform(X_train[[col]])\n",
    "                X_test_imputed[[col]] = imputer.transform(X_test[[col]])\n",
    "                print(f\"{col} sütunu için KNN imputation uygulandı.\")\n",
    "\n",
    "            elif method == 'regression':\n",
    "                X_train_temp = X_train.drop(col, axis=1)\n",
    "                y_train_temp = X_train[col]\n",
    "\n",
    "                X_train_not_null = X_train_temp[y_train_temp.notna()]\n",
    "                y_train_not_null = y_train_temp[y_train_temp.notna()]\n",
    "\n",
    "                model = LinearRegression()\n",
    "                model.fit(X_train_not_null, y_train_not_null)\n",
    "\n",
    "                X_train_null = X_train_temp[y_train_temp.isna()]\n",
    "                X_test_null = X_test[X_test[col].isna()].drop(col, axis=1, errors='ignore')  # Test setinde sütun olmayabilir\n",
    "\n",
    "                X_train_imputed.loc[X_train[col].isna(), col] = model.predict(X_train_null)\n",
    "                if not X_test_null.empty:\n",
    "                    X_test_imputed.loc[X_test[col].isna(), col] = model.predict(X_test_null)\n",
    "                print(f\"{col} sütunu için regresyon imputation uygulandı.\")\n",
    "            else:\n",
    "                raise ValueError(\"Geçersiz method. 'knn' veya 'regression' seçin.\")\n",
    "\n",
    "            print(f\"Eksik Değer Sayısı (Eğitim): {X_train_imputed[col].isnull().sum()}\")\n",
    "            print(f\"Eksik Değer Sayısı (Test): {X_test_imputed[col].isnull().sum()}\")\n",
    "\n",
    "    return X_train_imputed, X_test_imputed\n",
    "\n",
    "\n",
    "\"Kullanım örneği\"\n",
    "numeric_cols = X_train.select_dtypes(include=np.number).columns.tolist()  # Sayısal sütunları al\n",
    "\n",
    "X_train_imputed, X_test_imputed = intelligent_imputation(X_train.copy(), X_test.copy(), numeric_cols, method='knn', n_neighbors=5)\n",
    "\n",
    "# veya\n",
    "\n",
    "X_train_imputed, X_test_imputed = intelligent_imputation(X_train.copy(), X_test.copy(), numeric_cols, method='regression')\n",
    "\n",
    "# Artık X_train_imputed ve X_test_imputed'ı model eğitiminde kullanabilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"PCA İLE BOYUT İNDİRGEME\"\n",
    "\"Şart değil -T\"\n",
    "#PCA, özellikle yüksek korelasyonlu özellikler varsa faydalı olabilir.\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Veri setini ölçeklendirdikten sonra (yukarıdaki kodda)\n",
    "# PCA uygulaması\n",
    "pca = PCA(n_components=0.95)  # Toplam varyansın %95'ini koruyacak kadar bileşen seç\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "print(\"Orijinal Özellik Sayısı:\", X_train.shape[1])\n",
    "print(\"PCA Sonrası Özellik Sayısı:\", X_train_pca.shape[1])\n",
    "\n",
    "# Modeli PCA ile dönüştürülmüş verilerle eğitme\n",
    "model_pca = SVC(random_state=42)\n",
    "model_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = model_pca.predict(X_test_pca)\n",
    "\n",
    "print(\"\\nPCA ile Model Performansı:\")\n",
    "print(classification_report(y_test, y_pred_pca))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
